{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mosquito Classifier Tutorial v1\r\n",
    "## Author: Arvin Lin (林奕竹） Date: 2019 01 23\r\n",
    "This notebook will go through the process of using transfer learning to train the mosquito classifier. To run this notebook, open terminal and navigate to the directory where this notebook resides (/hdd/Train), then enter the following commands:\r\n",
    "\r\n",
    "source ~/.bashrc\r\n",
    "jupyter notebook\r\n",
    "The Home page of the jupyter notebook will be automatically opened in the web browser. In the Home page click on Mosquito Classifier Tutorial.ipynb to open this notebook\r\n",
    "\r\n",
    "(Notes: You can move this notebook along with the /hdd/Train/data to the SSD disk to run the program faster)\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Load the Required Libraries\r\n",
    "load the required libraries by running the following cell:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Easy Tutorial on how to perform transfer learning on SqueezeNet. \r\n",
    "#Author: Arvin Lin\r\n",
    "#Please do not modify the following codes unless you know what you are doing.\r\n",
    "#Keras\r\n",
    "from keras.models import Sequential, Model\r\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\r\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
    "from keras.optimizers import SGD,RMSprop,Adam\r\n",
    "from keras.utils import np_utils\r\n",
    "from keras.models import model_from_json\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, ModelCheckpoint\r\n",
    "from keras import applications\r\n",
    "from keras import regularizers\r\n",
    "\r\n",
    "#Squeezenet\r\n",
    "from keras_squeezenet import SqueezeNet\r\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\r\n",
    "from keras.preprocessing import image\r\n",
    "#from keras.preprocessing.image.ImageDataGenerator import flow_from_directory\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib\r\n",
    "import os\r\n",
    "from PIL import Image\r\n",
    "from numpy import *\r\n",
    "\r\n",
    "from sklearn.utils import shuffle\r\n",
    "#from sklearn.cross_validation import train_test_split\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Define the Hyper-Parameters for Taining\r\n",
    "Change the following variables to test which set of numbers gives the best training results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# these values can be altered to test\r\n",
    "# number of epochs to train\r\n",
    "batch_size = 64                     #recommendation: 16, 32, 64, ..., too big then may cost too much memory\r\n",
    "nb_epoch = 3                        #the bigger the number the longer it trains (ex 50)\r\n",
    "minus_layers = 10                   #how many layers would be subtracted in squeezenet\r\n",
    "freeze_layers = 10                  #how many layers would be non-trainable in squeezenet\r\n",
    "dense_num = 1024                    #recommendation: 256, 512, 1024, ...\r\n",
    "dropout_rate = 0.25                 #between 0~1\r\n",
    "learning_rate = 0.00001             #recommendation: 0.00001, 0.00003, 0.0001, 0.0003, ...\r\n",
    "ESP = 6                             #recommendation: don't set too high(Early Stopping Patience)\r\n",
    "RLROPP = 4                          #recommendation: don't set too high(RediceLROnPlateau Patience)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Define the Training Input Shape and Define a Data Generator\r\n",
    "Using a data generator can create more images to train by applying changes to existing images. In the following cell please follow the comments on how to modify the data generator. Do not change other lines of codes unless you know what you are doing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Do Not Chage These Lines\r\n",
    "#Define the input shape of the images\r\n",
    "img_rows, img_cols = 227, 227\r\n",
    "img_channels = 3\r\n",
    "\r\n",
    "## This Line Should be Changed Only When There Are More Types in the Image Dataset\r\n",
    "# number of output classes\r\n",
    "nb_classes = 3\r\n",
    "\r\n",
    "\r\n",
    "# Modify the ImageDataGenerator to Test for Different Configurations\r\n",
    "## Notice!!! Setting too much of the variables may result in very LONG training time !!!\r\n",
    "train_datagen = ImageDataGenerator(\r\n",
    "\trescale = 1./255,              # Do Not Change This Line !!!\r\n",
    "\t#rotation_range = 20,          # set rotation_range's number or comment out this line \r\n",
    "\t#zoom_range=0.1,               # Set zoom_range's number or comment out this line\r\n",
    "\t#width_shift_range=0.2,        # Set width_shift_range's number or comment out this line\r\n",
    "\t#height_shift_range=0.2,       # Set height_shift_range's number or comment out this line\r\n",
    "\t#shear_range=0.1,              # Set shear_range's number or comment out this line\r\n",
    "\t#horizontal_flip=True,         # Set horizontal_flip to True or False,  or comment out this line\r\n",
    "\t#vertical_flip=True            # Set vertical_flip to True or False,  or comment out this line\r\n",
    ")\r\n",
    "\r\n",
    "## Do Not Change The Following Lines\r\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "\t'data/train',\r\n",
    "\ttarget_size = (img_rows, img_cols),\r\n",
    "\tbatch_size = batch_size,\r\n",
    "\tclass_mode = 'categorical'\r\n",
    ")\r\n",
    "\r\n",
    "validation_generator = val_datagen.flow_from_directory(\r\n",
    "\t'data/val',\r\n",
    "\ttarget_size = (img_rows, img_cols),\r\n",
    "\tbatch_size = batch_size,\r\n",
    "\tclass_mode = 'categorical'\r\n",
    ")\r\n",
    "\r\n",
    "test_generator = test_datagen.flow_from_directory(\r\n",
    "\t'data/test',\r\n",
    "\ttarget_size = (img_rows, img_cols),\r\n",
    "\tbatch_size = batch_size,\r\n",
    "\tclass_mode = 'categorical'\r\n",
    ")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Load and Modify the SqueezeNet Model\r\n",
    "We use the SqueezeNet model becuase it is sufficiently small to run on Raspberry Pi and can attain a very good accuracy. Some of the following lines can be modified given that you have experience in Keras."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = SqueezeNet()\r\n",
    "#Freeze some layers, the number of freezed layers should be defined in Step 2.\r\n",
    "for layer in model.layers[:freeze_layers]:\r\n",
    "\tlayer.trainable = False\r\n",
    "#Pop out some layers, the number of popped layers should also be defined in Step 2.\r\n",
    "for i in range(minus_layers):\r\n",
    "\tmodel.layers.pop()\r\n",
    "#Get the output of the modified squeezenet\r\n",
    "x = model.output\r\n",
    "#Add custum layers\r\n",
    "x = Dense(dense_num, activation=\"relu\")(x)\r\n",
    "\r\n",
    "## Modify The Following Lines\r\n",
    "## Do So If You Know Keras\r\n",
    "\r\n",
    "x = Dropout(dropout_rate)(x)\r\n",
    "## Modify The Above Lines\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Do Not Modify the Following Lines\r\n",
    "predictions = Dense(nb_classes, activation = \"softmax\")(x)\r\n",
    "## Do Not Modify the Following Lines\r\n",
    "final_model = Model(input = model.input, output = predictions)   \r\n",
    "# Compile model\r\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\r\n",
    "#implement early stopping\r\n",
    "callback = [EarlyStopping(patience=ESP), \r\n",
    "\t    ReduceLROnPlateau(patience = RLROPP, verbose = 1),\r\n",
    "\t    CSVLogger(filename='log.csv'),\r\n",
    "\t    ModelCheckpoint('checkpoint' + '.check',\r\n",
    "\t    \t\t\tsave_best_only = True,\r\n",
    "\t\t\t\tsave_weights_only = True)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Train the Model\r\n",
    "After this step, 3 files would be created:\r\n",
    "\r\n",
    "model.json\r\n",
    "model.h5\r\n",
    "accuracy.txt\r\n",
    "\r\n",
    "The two model files contains the model and could be placed in the mosquito trap raspberry pi to predict mosquitoes. The accuracy.txt file saves the testing accuracy of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#start training\r\n",
    "hist = final_model.fit_generator(\r\n",
    "\t\t\t\ttrain_generator, \r\n",
    "\t\t\t\tepochs=nb_epoch, \r\n",
    "                steps_per_epoch = len(train_generator),\r\n",
    "\t\t\t\tverbose=1, \t\t\r\n",
    "\t\t\t\tvalidation_data= validation_generator, \r\n",
    "                validation_steps = len(validation_generator),\r\n",
    "\t\t\t\tcallbacks = callback)\r\n",
    "\r\n",
    "scores = final_model.evaluate_generator(test_generator, steps = len(test_generator), verbose=1)\r\n",
    "print(\"%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\r\n",
    "\r\n",
    "model_json = final_model.to_json()\r\n",
    "with open(\"model.json\",\"w\") as json_file:\r\n",
    "\tjson_file.write(model_json)\r\n",
    "\r\n",
    "final_model.save_weights(\"model.h5\")\r\n",
    "print(\"Saved model\")\r\n",
    "\r\n",
    "f = open('accuracy.txt','w')\r\n",
    "f.write(\"%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}